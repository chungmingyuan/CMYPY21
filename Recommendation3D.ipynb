{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "pymysql.install_as_MySQLdb()\n",
    "import smtplib\n",
    "from pretty_html_table import build_table\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.image import MIMEImage\n",
    "import datetime as dt\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "import plotly.express as px\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class DbConn:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        load_dotenv()\n",
    "        self.endpoint = os.getenv(\"DB_ACCESS_KEY\")\n",
    "        self.username = os.getenv(\"USERNAME\")\n",
    "        self.password = os.getenv(\"USERPASS\")\n",
    "       \n",
    "    def getDbConn(self):\n",
    "        db_connection_str = \"mysql+pymysql://\"+self.username+ \":\" +self.password +\"@\"+self.endpoint+\"/\"+ self.name\n",
    "        print(db_connection_str)\n",
    "        return sqlalchemy.create_engine(db_connection_str).connect()\n",
    "\n",
    "    def getDb(self):\n",
    "        return pymysql.connect(host=self.endpoint, user=self.username,passwd=self.password, database= self.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class GetTaReportParms:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        dbconn = DbConn(name)\n",
    "        self.conn = dbconn.getDbConn()\n",
    "        self.stkGrpLst = self.getStkGrpLst()\n",
    "        self.chgDaylst = self.getChgDayLst()\n",
    "        \n",
    "    def getStkGrpLst(self):\n",
    "        req = self.name+'.'+f'`Property`'\n",
    "        return pd.read_sql(f\"SELECT value FROM {req} where Type = 1\",self.conn).value.to_list()\n",
    "    def getChgDayLst(self):\n",
    "        req = self.name+'.'+f'`Property`'\n",
    "        return pd.read_sql(f\"SELECT CAST(value as SIGNED) value FROM {req} where Type = 2\",self.conn).value.to_list()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class StkGrpYfData:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        dbconn = DbConn(name)\n",
    "        self.conn = dbconn.getDbConn()\n",
    "\n",
    "    def gettables(self):\n",
    "        query = f\"\"\"SELECT table_name FROM information_schema.tables\n",
    "        WHERE table_schema = '{self.name}'\"\"\"\n",
    "        df = pd.read_sql(query, self.conn)\n",
    "        df['Schema'] = self.name\n",
    "        return df\n",
    "\n",
    "    def maxdate(self):\n",
    "        req = self.name+'.'+f'`{self.gettables().TABLE_NAME[0]}`'\n",
    "        return pd.read_sql(f\"SELECT MAX(Date) FROM {req}\",self.conn)\n",
    "\n",
    "    def updateDB(self):\n",
    "        maxdate=self.maxdate()['MAX(Date)'][0]\n",
    "        print('DB MaxDate =', maxdate)\n",
    "        for symbol in self.gettables().TABLE_NAME:\n",
    "            data = yf.download(symbol, start=maxdate)\n",
    "            data = data[data.index > maxdate]\n",
    "            data = data.reset_index()\n",
    "            data.to_sql(symbol, self.conn, if_exists='append')\n",
    "        print(f'{self.name} successfully updated')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class ProcStock:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        dbconn = DbConn(name)\n",
    "        self.conn = dbconn.getDbConn()\n",
    "\n",
    "    def gettables(self):\n",
    "        query = f\"\"\"SELECT table_name FROM information_schema.tables\n",
    "        WHERE table_schema = '{self.name}'\"\"\"\n",
    "        df = pd.read_sql(query, self.conn)\n",
    "        df['Schema'] = self.name\n",
    "        return df\n",
    "\n",
    "    def getprices(self):\n",
    "        prices = []\n",
    "        for table, schema in zip(self.gettables().TABLE_NAME, self.gettables().Schema):\n",
    "            req = schema+'.'+f'`{table}`'\n",
    "            prices.append(pd.read_sql(f\"SELECT * \\\n",
    "                FROM (SELECT Date, '{self.name}' as StkGrp, '{table}' as Symbol, Close FROM {req} ORDER BY Date desc Limit 201) SUB ORDER BY Date ASC\",self.conn))\n",
    "        return prices\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Recommendor:\n",
    "    def __init__(self, name, prices):\n",
    "        self.name = name\n",
    "        self.prices = prices\n",
    "        dbconn = DbConn(name)\n",
    "        self.conn = dbconn.getDbConn()\n",
    "        self.db = dbconn.getDb()\n",
    "   \n",
    "    def MACDdecision(self,df):\n",
    "        df['MACD_diff'] = ta.trend.macd_diff(df.Close)\n",
    "        df['Decision MACD'] = np.where((df.MACD_diff > 0) & (df.MACD_diff.shift(1) < 1), True, False)\n",
    "\n",
    "    def Goldencrossdecision(self,df):\n",
    "        df['SMA20'] = ta.trend.sma_indicator(df.Close, window=20)\n",
    "        df['SMA50'] = ta.trend.sma_indicator(df.Close, window=50)\n",
    "        df['GCSignal'] = np.where(df['SMA20'] > df['SMA50'], True, False)\n",
    "        df['Decision GC'] = df.GCSignal.diff()\n",
    "\n",
    "    def RSI_SMAdecision(self,df):\n",
    "        df['RSI'] = ta.momentum.rsi(df.Close, window=10)\n",
    "        df['SMA200'] = ta.trend.sma_indicator(df.Close, window=200)\n",
    "        df['Decision RSI/SMA'] = np.where((df.Close > df.SMA200) & (df.RSI < 30), True, False)\n",
    "\n",
    "    def applytechnicals(self):\n",
    "        for frame in self.prices:\n",
    "            self.MACDdecision(frame)\n",
    "            self.Goldencrossdecision(frame)\n",
    "            self.RSI_SMAdecision(frame)\n",
    " \n",
    "    def recommend(self):\n",
    "        indicators = ['Decision MACD','Decision GC','Decision RSI/SMA']\n",
    "        sigColumns=['Name','Symbol','Decision MACD','Decision GC','Decision RSI/SMA']\n",
    "        dfSignals=pd.DataFrame(columns=sigColumns)\n",
    "        self.applytechnicals()\n",
    "        mycursor = self.db.cursor()\n",
    "        \n",
    "        for frame in self.prices:\n",
    "            if frame.empty is False:\n",
    "                macd, gc, rsi, sig ='', '', '', ''\n",
    "                for indicator in indicators:\n",
    "                    if frame[indicator].iloc[-1] == True: # only chk today's result in the last row\n",
    "                        if 'Decision MACD' == indicator:\n",
    "                            macd, sig = 'X', 'MACD'\n",
    "                        if 'Decision GC' == indicator:\n",
    "                            gc, sig = 'X', 'GC' \n",
    "                        if 'Decision RSI/SMA' == indicator:\n",
    "                            rsi, sig = 'X', 'RSI'\n",
    "                if sig != '':\n",
    "                    dfDb = frame.tail(1)\n",
    "                    dfDb=dfDb.set_index('Date')\n",
    "                    # print(dfDb.head())\n",
    "                    # delete the row if already exists\n",
    "                    # print(type(dfDb),'@@@@@@',dfDb.index.values[0],'+++++++++++',dfDb.iloc[0][0],'-------',dfDb.iloc[0][1])\n",
    "                    sql = f\"DELETE FROM Result WHERE Date = '{dfDb.index.values[0]}' and StkGrp = '{dfDb.iloc[0][0]}' and Symbol = '{dfDb.iloc[0][1]}'\"\n",
    "                    # print('==========',sql)\n",
    "                    mycursor.execute(sql)\n",
    "                    self.db.commit()    \n",
    "                    # add to DB\n",
    "                    dfDb.to_sql('Result', self.conn, if_exists='append')\n",
    "\n",
    "                    # add to report\n",
    "                    dfSignals = dfSignals.append(\n",
    "                        {\n",
    "                        'Name': self.name,\n",
    "                        'Symbol' : frame['Symbol'][0],\n",
    "                        'Decision MACD' : macd,\n",
    "                        'Decision GC' : gc,\n",
    "                        'Decision RSI/SMA' : rsi,\n",
    "                        'Signal' : sig\n",
    "                        },ignore_index=True\n",
    "                    )\n",
    "        \n",
    "        return dfSignals.set_index('Name')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class CreateEmails:\n",
    "    smtp_server ='smtp.gmail.com'\n",
    "    port = 587\n",
    "    def __init__(self, name, dfSignals, pdf):\n",
    "        self.name = name\n",
    "        self.dfSignals =dfSignals\n",
    "        self.pdf = pdf\n",
    "        self.sender = os.getenv(\"SENDER_EMAIL\")\n",
    "        self.receivers = os.getenv(\"RECEIVER_EMAILS\")\n",
    "        self.password = os.getenv(\"PASSWORD\")\n",
    "        \n",
    "        \n",
    "    def sendEmails(self):    \n",
    "        message = MIMEMultipart()\n",
    "        message['Subject'] = f'{self.name} buying signals report'\n",
    "        message['From'] = self.sender\n",
    "        message['To'] = self.receivers\n",
    "        now = dt.datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "        header = f'<h2>{self.name} buying signals report created at {now}</h2>'\n",
    "        body = build_table(self.dfSignals, \"green_light\",text_align =\"center\")\n",
    "        footer = f'<h2>Good Luck!!!</h2>'\n",
    "        \n",
    "        img = MIMEImage(self.pdf, \"pdf\" )\n",
    "        img.add_header('Content-Disposition', 'attachment', filename=self.name+\".pdf\")\n",
    "        body_content = header + body + footer\n",
    "        message.attach(MIMEText(body_content, \"html\"))\n",
    "        message.attach(img)\n",
    "        msg_body = message.as_string()\n",
    "        server =smtplib.SMTP(self.smtp_server, self.port)\n",
    "        server.starttls()\n",
    "        server.login(self.sender,self.password)\n",
    "        server.sendmail(self.sender,self.receivers,msg_body)\n",
    "        #\n",
    "        server.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class DbQuoteData:\n",
    "    def __init__(self, name, tickers_lst):\n",
    "        self.name = name\n",
    "        self.tickers_lst = tickers_lst\n",
    "        self.conn = self.getDbConn(name)\n",
    "\n",
    "    def getDbConn(self,name):\n",
    "        dbconn = DbConn(name)\n",
    "        return dbconn.getDbConn()\n",
    "\n",
    "    def gettables(self):\n",
    "        query = f\"\"\"SELECT table_name FROM information_schema.tables\n",
    "        WHERE table_schema = '{self.name}'\"\"\"\n",
    "        df = pd.read_sql(query, self.conn)\n",
    "        df['Schema'] = self.name\n",
    "        return df\n",
    "\n",
    "        \n",
    "\n",
    "    # Step1: Calcualte the start and end dates based on the input days from the valid NYSC calendar\n",
    "    def get_start_end_dates(self,day):\n",
    "    # get the last valid NYSE bus dates for the last 40 calendar dates using market calendar\n",
    "        nyse = mcal.get_calendar('NYSE')\n",
    "        schedule_nyse = nyse.schedule(\n",
    "            (dt.datetime.today()-dt.timedelta(40)).strftime(\"%Y-%m-%d\"),\n",
    "            dt.datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "    #check today's market closed or not\n",
    "        if dt.datetime.now(dt.timezone.utc).hour >= schedule_nyse.market_close[-1].hour:\n",
    "            market_closed_indicator = 0 # now is after 4PM ET- market closed-- we have today's data\n",
    "        else:\n",
    "            market_closed_indicator = 1  # else yesterday's data      \n",
    "        end = schedule_nyse.market_close[-1-market_closed_indicator].strftime(\"%Y-%m-%d\")\n",
    "        start = schedule_nyse.market_close[-day - market_closed_indicator].strftime(\"%Y-%m-%d\")\n",
    "        return start, end\n",
    "    def getDbCloseQuote(self, symbol, date):\n",
    "        req = self.name+'.'+f'`{symbol}`'\n",
    "        sql = f\"SELECT `Adj Close` FROM {req} where Date = '{date}'\"\n",
    "        result = self.conn.execute(sql)\n",
    "        adjCloseQ = 0.0\n",
    "        for row in result:\n",
    "            adjCloseQ = row['Adj Close']\n",
    "        return adjCloseQ\n",
    "    def calcChgs(self,symbol,start,end):\n",
    "        startQ= self.getDbCloseQuote(symbol,start)\n",
    "        endQ= self.getDbCloseQuote(symbol,end)\n",
    "        if (endQ == 0.0) :\n",
    "            return 0.0\n",
    "        else:\n",
    "            return (endQ-startQ)/startQ*100\n",
    "    # Step2: Get the quotes data from Database based on the input parm 'days'\n",
    "    def calc_percent_chgs(self,day):\n",
    "        start, end = self.get_start_end_dates(day) #call step1\n",
    "        # print(f'get quotes start---{dt.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}')\n",
    "        print(f'Start Date={start}  End Date={end}')\n",
    "        chgs=[]\n",
    "        for symbol in self.tickers_lst:\n",
    "            chg = self.calcChgs(symbol,start, end)\n",
    "            chgs.append(chg)\n",
    "        return chgs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class TksChgsByDays:\n",
    "    #days_lst = (2,5,10) # 1D/1W/2W\n",
    "    def __init__(self, name, tks, days):\n",
    "        self.name = name\n",
    "        self.tks = tks\n",
    "        self.days =days    \n",
    "    def get_chgs(self):\n",
    "        tksChgsByDays = []\n",
    "        dbQuoteData =DbQuoteData(self.name, self.tks)\n",
    "        for day in self.days:\n",
    "            tkerChgs = dbQuoteData.calc_percent_chgs(day)\n",
    "            tksChgsByDays.append(tkerChgs) \n",
    "        return tksChgsByDays"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class PlotChgs:\n",
    "    def __init__(self, name, chgs):\n",
    "        self.name = name\n",
    "        self.chgs = chgs\n",
    "    def doPlot(self):\n",
    "        fig = px.bar(self.chgs,width=1000, height=400)\n",
    "        fig.update_layout(barmode = 'group', bargap = 0.2, bargroupgap = 0.0)\n",
    "        fig.update_layout(\n",
    "            title=self.name + \" Percentage Changes\",\n",
    "            title_x=0.5,\n",
    "            xaxis_tickangle=-45,\n",
    "            xaxis_showticklabels= True,\n",
    "            xaxis_type = 'category',\n",
    "            xaxis_title=\"Symbols\",\n",
    "            yaxis_title=\"Percentage\",\n",
    "            legend_title=\"Days\",\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=18,\n",
    "                color=\"RebeccaPurple\"\n",
    "            )\n",
    "        )\n",
    "        fig.show()\n",
    "        pdf = fig.to_image(format=\"pdf\")  \n",
    "        return pdf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class StockGrpBuyingReport:\n",
    "    def __init__(self,name, days):\n",
    "        self.name = name\n",
    "        self.days = days\n",
    "    def createBuyingRpt(self):\n",
    "    # get stock prices\n",
    "        stkGrp = ProcStock(self.name)\n",
    "        prices = stkGrp.getprices()\n",
    "    # create report\n",
    "        stkRecommendor = Recommendor('TA',prices)\n",
    "        dfStkGrpSignals =stkRecommendor.recommend()\n",
    "    # create changes\n",
    "        if not dfStkGrpSignals.empty:\n",
    "            stkGrpSymbolLst =dfStkGrpSignals.Symbol.to_list()\n",
    "            stkGrpChgsByDays = TksChgsByDays(self.name, stkGrpSymbolLst, self.days)\n",
    "            stkGrpTksChgsByDays = stkGrpChgsByDays.get_chgs()\n",
    "            # print(dfStkGrpSignals) \n",
    "            df = pd.DataFrame(stkGrpTksChgsByDays).transpose()\n",
    "            df['Symbol']= ('(' + dfStkGrpSignals.Signal +') ' + dfStkGrpSignals.Symbol).to_list() # remove signal col\n",
    "            df=df.set_index('Symbol',drop = True)\n",
    "            daysNames =[]\n",
    "            for day in self.days:\n",
    "                daysNames.append(str(day)+'days Chgs')\n",
    "            df.columns = daysNames\n",
    "            # print(df)\n",
    "        \n",
    "    # create plot\n",
    "            stkGrpchgsPlot=PlotChgs(self.name, df)\n",
    "            svg = stkGrpchgsPlot.doPlot()\n",
    "        \n",
    "    # create email\n",
    "            stkGrpEmails = CreateEmails(self.name,dfStkGrpSignals.drop(columns=['Signal']),svg) #remove signal col\n",
    "            stkGrpEmails.sendEmails()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class ArkxEtfLstBuyingRpt:\n",
    "    def __init__(self,etfLst, days):\n",
    "        self.etfLst = etfLst\n",
    "        self.days = days\n",
    "    def createArkxEtfBuyingRpt(self):\n",
    "        for etf in self.etfLst:\n",
    "            etfStockGrpBuyingReport = StockGrpBuyingReport(etf, self.days)\n",
    "            etfStockGrpBuyingReport.createBuyingRpt()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Daily process\n",
    "# 1. Get process parms from DB\n",
    "procParms = GetTaReportParms('TA')\n",
    "# 1. update DB with yfdata\n",
    "# procParms.stkGrpLst = ['SP100'] #TESTING\n",
    "for stkGrp in procParms.stkGrpLst:\n",
    "    stkGrpYfData = StkGrpYfData(stkGrp)\n",
    "    stkGrpYfData.updateDB()\n",
    "# 2. Create TA reports based on the parms in the TA db\n",
    "arkxEtfLstBuyingRpt = ArkxEtfLstBuyingRpt(procParms.stkGrpLst,procParms.chgDaylst)\n",
    "# arkxEtfLstBuyingRpt = ArkxEtfLstBuyingRpt(['ARKK','ARKF','ARKW','ARKQ','ARKX','ARKG','CMY1','DJIA','SP100'],[2,5,10])\n",
    "# arkxEtfLstBuyingRpt = ArkxEtfLstBuyingRpt(['ARKK'],[2,5,10])\n",
    "arkxEtfLstBuyingRpt.createArkxEtfBuyingRpt()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mysql+pymysql://root:12344321@localhost/TA\n",
      "mysql+pymysql://root:12344321@localhost/SP100\n",
      "DB MaxDate = 2021-09-08 00:00:00\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SP100 successfully updated\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# etfStockGrpBuyingReport = StockGrpBuyingReport('ARKK',[2,5,10])\n",
    "# etfStockGrpBuyingReport.createBuyingRpt()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# djia = Recommender('djia')\n",
    "# djia.updateDB()\n",
    "# dfdjiaSignals =djia.recommend()\n",
    "# djiaEmails = CreateEmails('DJIA',dfdjiaSignals)\n",
    "# djiaEmails.sendEmails()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# arkk = Recommender('arkk')\n",
    "# # arkk.updateDB()\n",
    "# dfarkkSignals =arkk.recommend()\n",
    "# print(dfarkkSignals)\n",
    "# tkersLst = dfarkkSignals.Symbol.to_list()\n",
    "# print(tkersLst)\n",
    "# DbQuoteData =DbQuoteData('arkk', tkersLst,2)\n",
    "# chgs = DbQuoteData.calc_percent_chgs()\n",
    "# # arkkEmails = CreateEmails('ARKK',dfarkkSignals)\n",
    "# # arkkEmails.sendEmails()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}